---
# EXPERIMENT METADATA
# model_comment (optional) will end up in the model_comment column of the
# models table for each model created in this experiment
model_comment: 'test'

# TIME SPLITTING
# The time window to look at, and how to divide the window into
# train/test splits
temporal_config:
    beginning_of_time: '1995-01-01' # earliest date included in features
    modeling_start_time: '2012-01-01' # earliest date in any model
    modeling_end_time: '2015-01-01' # all dates in any model are < this date
    update_window: '6month' # how frequently to retrain models
    train_example_frequency: '1day' # time between rows for same entity in train matrix
    test_example_frequency: '3month' # time between rows for same entity in test matrix
    train_durations: ['6month', '3month'] # length of time included in a train matrix
    test_durations: ['1month', '2month'] # length of time included in a test matrix
    train_label_windows: ['1month'] # time period across which outcomes are labeled in train matrices
    test_label_windows: ['7day'] # time period across which outcomes are labeled in test matrices

# LABEL GENERATION
# Information needed to generate labels
#
# An events table is expected, with the columns:
#   entity_id - an identifier for which the labels are applied to
#   outcome_date - The date at which some outcome was known
#   outcome - A boolean outcome
# These are used to generate appropriate labels for each train/test split
events_table: 'events'


# FEATURE GENERATION
# The aggregate features to generate for each train/test split
#
# Implemented by wrapping collate: https://github.com/dssg/collate
# Most terminology here is taken directly from collate
#
# Each entry describes a collate.SpacetimeAggregation object, and the
# arguments needed to create it. Generally, each of these entries controls
# the features from one source table, though in the case of multiple groups
# may result in multiple output tables
feature_aggregations:
    -
        # prefix given to the resultant tables
        prefix: 'prefix'
        # from_obj is usually a source table but can be an expression, such as
        # a join (ie 'cool_stuff join other_stuff using (stuff_id)')
        from_obj: 'cool_stuff'
        # The date column to use for specifying which records to include
        # in temporal features. It is important that the column used specifies
        # the date at which the event is known about, which may be different
        # from the date the event happened.
        knowledge_date_column: 'open_date'

        # aggregates and categoricals define the actual features created. So
        # at least one is required
        #
        # Aggregates of numerical columns. Each quantity is a number of some
        # sort, and the list of metrics are applied to each quantity
        aggregates:
            -
                quantity: 'homeless::INT'
                metrics:
                    - 'count'
                    - 'sum'
        # Categorical features. The column given can be of any type, but the
        # choices must comparable to that type for equality within SQL
        # The result will be one feature for each choice/metric combination
        categoricals:
            -
                column: 'color'
                choices:
                    - 'red'
                    - 'blue'
                    - 'green'
                metrics:
                    - 'sum'
            -
                column: 'shape'
                choice_query: 'select distinct shape from cool_stuff'
                metrics:
                    - 'sum'
        # The time intervals over which to aggregate features
        intervals:
            - '1 year'
            - '2 years'
            - 'all'
        # A list of different columns to separately group by
        groups:
            - 'entity_id'

# FEATURE GROUPING
# define how to group features and generate combinations
# feature_group_definition allows you to create groups/subset of your features
# by different criteria.
# for instance, 'tables' allows you to send a list of collate feature tables
# 'prefix' allows you to specify a list of feature name prefixes
feature_group_definition:
    tables: ['prefix_entity_id']

# strategies for generating combinations of groups
# available: all, leave-one-out, leave-one-in
feature_group_strategies: ['all']

# STATE MANAGEMENT (optional)
# If you want to only include rows in your matrices in a specific state,
# provide:
# 1. a dense state table that defines when entities were in specific states
#   should have columns entity_id/state/start/end
# 2. a list of state filtering SQL clauses to iterate through. Assuming the
#   states are boolean columns (the experiment will convert the one you pass in
#   to this format), write a SQL expression for each state
#   configuration you want, ie '(permitted OR suspended) AND licensed'
state_config:
    table_name: 'states'
    state_filters:
        - 'state_one AND state_two'
        - '(state_one OR state_two) AND state_three'

# MODEL GROUPING
# Model groups are aimed at defining models which are equivalent across time splits.
# By default, the classifier module name, hyperparameters, and feature names are used.
#
# model_group_keys defines a list of *additional* matrix metadata keys that
# should be considered when creating a model group
model_group_keys:
    - 'train_duration'
    - 'train_label_window'
    - 'train_example_frequency'

# GRID CONFIGURATION
# The classifier/hyperparameter combinations that should be trained
#
# Each top-level key should be a class name, importable from triage. sklearn is
# available, and if you have another classifier package you would like available,
# contribute it to requirements.txt
#
# Each lower-level key is a hyperparameter name for the given classifier, and
# each value is a list of potential values. All possible combinations of
# classifiers and hyperparameters are trained.
grid_config:
    'sklearn.ensemble.ExtraTreesClassifier':
        n_estimators: [100,100]
        criterion: [gini, entropy]
        max_depth: [1,5,10,20,50]
        max_features: [sqrt,log2]
        min_samples_split: [2,5,10]
# MODEL SCORING
# How each trained model is scored
#
# Each entry in 'metric_groups' needs a list of one of the metrics defined in
# catwalk.evaluation.ModelEvaluator.available_metrics (contributions welcome!)
# Depending on the metric, either thresholds or parameters
#
# Parameters specify any hyperparameters needed. For most metrics,
# which are simply wrappers of sklearn functions, these
# are passed directly to sklearn.
#
# Thresholds are more specific: The list is subset and only the
# top percentile or top n entities are scored
#
# sort_seed, if passed, will seed the random number generator for each model's
# metric creation phase. This affects how entities with the same probabilities
# are sorted
scoring:
    sort_seed: 5
    metric_groups:
        -
            metrics: [precision@, recall@]
            thresholds:
                percentiles: [5.0, 10.0]
                top_n: [5, 10]
        -
            metrics: [f1]
        -
            metrics: [fbeta@]
            parameters:
                -
                    beta: 0.75
                -
                    beta: 1.25
